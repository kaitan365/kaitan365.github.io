{
  "hash": "ca6ab757638588a979b64ff1f0afa410",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Accelerating Your Python Code: Tips for Faster Performance\"\nauthor: \"Kai Tan\"\ndate: \"2024-05-01\"\ncategories: [Python]\nformat:\n  html:\n    code-fold: false\njupyter: python3\n---\n\nIn this blog post, I will explore several techniques to accelerate your Python code and enhance its performance.\n\n## Use broadcasting to avoid creating a diagonal matrix\n    \n- Use `A * v` instead of `A @ np.diag(v)`\n- Use `v[:, np.newaxis] * A` instead of `np.diag(v) @ A`\n\n::: {#227851fc .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport timeit\nA = np.random.randn(1000, 1000)\nv = np.random.randn(1000)\nassert np.all( A @ np.diag(v) == A * v )\nassert np.all( np.diag(v) @ A == v[:, np.newaxis] * A )\nprint('time for method 1:', timeit.timeit(lambda: A @ np.diag(v), number=10))\nprint('time for method 2:', timeit.timeit(lambda: A * v, number=10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntime for method 1: 0.18757016599999998\ntime for method 2: 0.005711124999999928\n```\n:::\n:::\n\n\n## Avoid large matrix multiplication\n\n- Use `np.einsum('ij,ji->', A, B)` instead of `np.trace(A @ B)`\n\n::: {#64e62651 .cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\nimport timeit\nA = np.random.randn(1000, 1000)\nB = np.random.randn(1000, 1000)\nassert np.isclose(np.trace(A @ B), np.einsum('ij,ji->', A, B))\nprint('time for method 1:', timeit.timeit(lambda: np.trace(A @ B), number=10))\nprint('time for method 2:', timeit.timeit(lambda: np.einsum('ij,ji->', A, B), number=10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntime for method 1: 0.1677121669999999\ntime for method 2: 0.010563332999999897\n```\n:::\n:::\n\n\n## Prioritize the order of matrix multiplication\n\n- Use `A @ (B @ v)` instead of `A @ B @ v` when v is a vector or an array of smaller size. \n\n::: {#991d246a .cell execution_count=3}\n``` {.python .cell-code}\nimport numpy as np\nimport timeit\nA = np.random.randn(1000, 1000)\nB = np.random.randn(1000, 1000)\nv = np.random.randn(1000)\nassert np.allclose(A @ B @ v, A @ (B @ v))\nprint('time for method 1:', timeit.timeit(lambda: A @ B @ v, number=10))\nprint('time for method 2:', timeit.timeit(lambda: A @ (B @ v), number=10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntime for method 1: 0.15922845799999985\ntime for method 2: 0.0014511249999999976\n```\n:::\n:::\n\n\n",
    "supporting": [
      "blog_efficient_compute_files"
    ],
    "filters": [],
    "includes": {}
  }
}